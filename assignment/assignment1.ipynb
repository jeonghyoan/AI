{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ORnGHCPhM1"
      },
      "source": [
        "## Assignment #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbQVdrrapfG_"
      },
      "source": [
        "* Release date: 2023.09.27 Wed\n",
        "* Due date: **2023.10.06 Fri 23:59** (will not accept late submission)\n",
        "* Submission format: notebook file which can be executed in Colab environment\n",
        "* Weighting: 5% (total 50 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVtMwumpcUu"
      },
      "source": [
        "1. **(10pts)** Calculate `rotation*x` and `x*rotation`. Explain how each computation is performed and why two results are the same.\n",
        "\n",
        "  ```python\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array([[2, 0]])\n",
        "    rotation = np.array([ [0, -1],\n",
        "                          [1,  0] ])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[2, 0]])\n",
        "rotation = np.array([[0, -1], [1, 0]])\n",
        "\n",
        "result1 = x*rotation\n",
        "result2 = rotation*x\n",
        "\n",
        "print(\"rotation * x:\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nx * rotation:\")\n",
        "print(result2)\n",
        "\n",
        "#x and rotation are NumPy arrays. NumPy array multiplication(*), in this problem, performs 'element-wise multiplication' rather than matrix multiplication(dot).\n",
        "#This means that it multiplies corresponding elements independently\n",
        "#Due to broadcasting, x is expanded to match the shape of rotation, resulting in [[2, 0], [2, 0]]\n",
        "# x*rotation is [[2*0, 0*-1], [2*1, 0*0]], therefore the result is [[0, 0], [2, 0]]\n",
        "# rotation * x is [[0*2, -1*0], [1*2, 0*0]]\n",
        "# element-wise multiplication is commutative, meaning the order of multiplication does not affect the outcome.\n",
        "# Therefore, both rotation * x and x * rotation produce the same result.\n"
      ],
      "metadata": {
        "id": "QE64ZlAi4gky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b68080-31d3-4b9c-f3b8-01f3d4296ae2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rotation * x:\n",
            "[[0 0]\n",
            " [2 0]]\n",
            "\n",
            "x * rotation:\n",
            "[[0 0]\n",
            " [2 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[[2*0, 0*-1],\n",
        " [2*1, 0*0]]"
      ],
      "metadata": {
        "id": "d5WjQQOAkkxY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARQKCA9sCpN-"
      },
      "source": [
        "2. **(5pts)** Suppose we have the following 2D tensor (i.e., a matrix). How to rearrange its values into 1D tensor (i.e., a vector) in a column major order?\n",
        "```python\n",
        "x = np.array([[1,  2,  3,  4],\n",
        "                 [5,  6,  7,  8],\n",
        "                 [9, 10, 11, 12]])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,  2,  3,  4],\n",
        "              [5,  6,  7,  8],\n",
        "              [9, 10, 11, 12]])\n",
        "\n",
        "# Use the flatten function to convert the matrix to a 1D array in column major order\n",
        "result = x.flatten(order='F')\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZyLHD1Y_cSY",
        "outputId": "5d78fd1c-cada-495c-9c5d-dfe27cf5217a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  5  9  2  6 10  3  7 11  4  8 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0cUrs6OFJVn"
      },
      "source": [
        "3. **(5pts)** Compute a transpose of the matrix `x` in Problem 2 by using only `np.reshape` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [9, 10, 11, 12]])\n",
        "\n",
        "x_transposed = np.reshape(x, (-1,), order='F')\n",
        "\n",
        "x_transposed = np.reshape(x_transposed, (x.shape[1], x.shape[0]))\n",
        "\n",
        "print(x_transposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqyVAfX3Cj0k",
        "outputId": "5e6150fa-a4e8-4316-c5a1-54bfe8e39ad0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  5  9]\n",
            " [ 2  6 10]\n",
            " [ 3  7 11]\n",
            " [ 4  8 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVzaCbniHnF6"
      },
      "source": [
        "4. **(5pts)** Perform vector arithmetic to create a `primes_squared_minus_one` vector, where the `i`th element is equal to the `i`th element in `primes` squared minus 1. For example, the second element of `primes_squared_minus_one` would be equal to `3^2 - 1 = 8`. Note that using `for` loop is not allowed.\n",
        "```python\n",
        "import numpy as np\n",
        "primes = np.array([2, 3, 5, 7, 11, 13])\n",
        "primes_squared_minus_one = ?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "primes = np.array([2, 3, 5, 7, 11, 13])\n",
        "primes_squared_minus_one = primes ** 2 - 1\n",
        "\n",
        "print(primes_squared_minus_one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1mD3vusH8li",
        "outputId": "8f9d164f-4ea1-4908-b2cf-1ad4397fa0bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  3   8  24  48 120 168]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGIhrK8hVgjh"
      },
      "source": [
        "5. **(10pts)** Given any random matrices, compute the element-wise multiplication using a naive Python implementation and Numpy built-in function respectively. Compare the wall-clock times of these implementations as the size of matrices increases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The NumPy implementation is much faster than the naiveÂ Python implementation.\n",
        "#As the matrix size increases this speed differential becomes more obvious"
      ],
      "metadata": {
        "id": "G4dXu7FnuASG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "GLYUrlJe12GW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naive element-wise matrix multiplication\n",
        "def naive_matrix_multiply(matrix1, matrix2):\n",
        "    result = []\n",
        "    for i in range(len(matrix1)):\n",
        "        row = []\n",
        "        for j in range(len(matrix1[0])):\n",
        "            row.append(matrix1[i][j] * matrix2[i][j])\n",
        "        result.append(row)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "p-Q2oep2zI1u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measure wall-clock time for matrix multiplication\n",
        "def measure_matrix_multiplication_time(matrix_size, num_tests=10):\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # Generate random matrices of the specified size\n",
        "    matrix1 = np.random.rand(matrix_size, matrix_size)\n",
        "    matrix2 = np.random.rand(matrix_size, matrix_size)\n",
        "\n",
        "    # Measure time for NumPy element-wise multiplication\n",
        "    numpy_start_time = time.time()\n",
        "    for _ in range(num_tests):\n",
        "        result = np.multiply(matrix1, matrix2)\n",
        "    numpy_end_time = time.time()\n",
        "    numpy_time = (numpy_end_time - numpy_start_time) / num_tests\n",
        "\n",
        "    # Convert matrices to lists for naive implementation\n",
        "    matrix1_list = matrix1.tolist()\n",
        "    matrix2_list = matrix2.tolist()\n",
        "\n",
        "    # Measure time for naive Python element-wise multiplication\n",
        "    naive_start_time = time.time()\n",
        "    for _ in range(num_tests):\n",
        "        result = naive_matrix_multiply(matrix1_list, matrix2_list)\n",
        "    naive_end_time = time.time()\n",
        "    naive_time = (naive_end_time - naive_start_time) / num_tests\n",
        "\n",
        "    return numpy_time, naive_time"
      ],
      "metadata": {
        "id": "yeMBxDysy6u7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different matrix sizes and compare execution times\n",
        "matrix_sizes = [1, 10, 100, 1000]\n",
        "\n",
        "for size in matrix_sizes:\n",
        "    numpy_time, naive_time = measure_matrix_multiplication_time(size)\n",
        "    print(f\"Matrix Size: {size}x{size}\")\n",
        "    print(f\"NumPy Time: {numpy_time:.6f} seconds\")\n",
        "    print(f\"Naive Python Time: {naive_time:.6f} seconds\")\n",
        "    print(\"=\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9OUKSgoy7IQ",
        "outputId": "c054ac27-b614-4238-97e4-d83d9598f44d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Size: 1x1\n",
            "NumPy Time: 0.000003 seconds\n",
            "Naive Python Time: 0.000001 seconds\n",
            "========================================\n",
            "Matrix Size: 10x10\n",
            "NumPy Time: 0.000004 seconds\n",
            "Naive Python Time: 0.000019 seconds\n",
            "========================================\n",
            "Matrix Size: 100x100\n",
            "NumPy Time: 0.000007 seconds\n",
            "Naive Python Time: 0.000956 seconds\n",
            "========================================\n",
            "Matrix Size: 1000x1000\n",
            "NumPy Time: 0.000998 seconds\n",
            "Naive Python Time: 0.145879 seconds\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDe6_vqqSe7f"
      },
      "source": [
        "6. **(15pts)** Consider MNIST classification problem covered during the class. For the details, please refer to the course material. In this example, we used the multilayer perceptron composed of an input layer with 512 hidden nodes and an output layer that produces predicted probabilities over 10 classes. In the class, we used GPU as a hardware accelerator to train our model.\n",
        "\n",
        "  Here, let's verify the actual benefit of using GPU for training. For this, compare the wall-clock times in the case of 1) using CPU and 2) using GPU to train MNIST classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import time"
      ],
      "metadata": {
        "id": "8sPLKXSouMx2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGjYUOpB8jNE",
        "outputId": "ad2721e4-3275-41eb-8a2f-f67786840195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Train on CPU\n",
        "start_time_cpu = time.time()\n",
        "model.fit(train_images, train_labels, epochs=15, validation_data=(test_images, test_labels))\n",
        "end_time_cpu = time.time()\n",
        "training_time_cpu = end_time_cpu - start_time_cpu\n",
        "\n",
        "print(f\"Training on CPU took {training_time_cpu} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPMwBvYe8jaQ",
        "outputId": "81b2b6ce-5d87-4738-dfbd-628b8e1b0416"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.5826 - accuracy: 0.9073 - val_loss: 0.5138 - val_accuracy: 0.9242\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3674 - accuracy: 0.9337 - val_loss: 0.3700 - val_accuracy: 0.9368\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3091 - accuracy: 0.9397 - val_loss: 0.3079 - val_accuracy: 0.9369\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2621 - accuracy: 0.9467 - val_loss: 0.3545 - val_accuracy: 0.9367\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2526 - accuracy: 0.9490 - val_loss: 0.4820 - val_accuracy: 0.9307\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2295 - accuracy: 0.9534 - val_loss: 0.4183 - val_accuracy: 0.9355\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2185 - accuracy: 0.9563 - val_loss: 0.3139 - val_accuracy: 0.9494\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2032 - accuracy: 0.9591 - val_loss: 0.3478 - val_accuracy: 0.9442\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1918 - accuracy: 0.9603 - val_loss: 0.3591 - val_accuracy: 0.9473\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2025 - accuracy: 0.9608 - val_loss: 0.3486 - val_accuracy: 0.9483\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1807 - accuracy: 0.9642 - val_loss: 0.4193 - val_accuracy: 0.9501\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1874 - accuracy: 0.9638 - val_loss: 0.4098 - val_accuracy: 0.9481\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1845 - accuracy: 0.9669 - val_loss: 0.3898 - val_accuracy: 0.9490\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1828 - accuracy: 0.9669 - val_loss: 0.4083 - val_accuracy: 0.9531\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1710 - accuracy: 0.9683 - val_loss: 0.4604 - val_accuracy: 0.9453\n",
            "Training on CPU took 112.47414231300354 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I executed the code with 'with tf.device('/GPU:0')', but the execution time was similar,\n",
        "#so I assumed that the code was not running on the GPU.\n",
        "#Therefore, I manually changed the runtime type to GPU from here.\n",
        "#So, before this cell, it was running on CPU, and from this cell onwards, it was running on GPU.\n",
        "\n",
        "\n",
        "\n",
        "# 2) Train on GPU\n",
        "start_time_gpu = time.time()\n",
        "model.fit(train_images, train_labels, epochs=15, validation_data=(test_images, test_labels))\n",
        "end_time_gpu = time.time()\n",
        "training_time_gpu = end_time_gpu - start_time_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qewheGV8jic",
        "outputId": "0ba4fce7-563b-432e-b59c-f61873bd4dc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1397 - accuracy: 0.9762 - val_loss: 0.6883 - val_accuracy: 0.9555\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1264 - accuracy: 0.9772 - val_loss: 0.7198 - val_accuracy: 0.9540\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1397 - accuracy: 0.9765 - val_loss: 0.6689 - val_accuracy: 0.9579\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1309 - accuracy: 0.9773 - val_loss: 0.6990 - val_accuracy: 0.9564\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1424 - accuracy: 0.9772 - val_loss: 0.7832 - val_accuracy: 0.9596\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1414 - accuracy: 0.9778 - val_loss: 0.8224 - val_accuracy: 0.9560\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1282 - accuracy: 0.9785 - val_loss: 0.8401 - val_accuracy: 0.9569\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1358 - accuracy: 0.9781 - val_loss: 0.8117 - val_accuracy: 0.9593\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9788 - val_loss: 0.7739 - val_accuracy: 0.9585\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1356 - accuracy: 0.9778 - val_loss: 0.8555 - val_accuracy: 0.9562\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1230 - accuracy: 0.9796 - val_loss: 0.8746 - val_accuracy: 0.9560\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1332 - accuracy: 0.9788 - val_loss: 0.8341 - val_accuracy: 0.9564\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9806 - val_loss: 1.0016 - val_accuracy: 0.9572\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1147 - accuracy: 0.9806 - val_loss: 0.9254 - val_accuracy: 0.9590\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1270 - accuracy: 0.9798 - val_loss: 0.9982 - val_accuracy: 0.9542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training on GPU took {training_time_gpu} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejh8LLshBJIj",
        "outputId": "86f3f65b-9e22-4081-f901-01c26972f6fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU took 83.97867560386658 seconds\n"
          ]
        }
      ]
    }
  ]
}